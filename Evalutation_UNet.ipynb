{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22bbbb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import ignite\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pytorch_ssim\n",
    "from ignite.metrics import SSIM, PSNR\n",
    "import glob\n",
    "import numpy as np\n",
    "from monai.networks.nets import UNet\n",
    "import monai\n",
    "from monai import transforms\n",
    "from monai.utils import set_determinism, first\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from monai.transforms import(\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    EnsureChannelFirstd,\n",
    "    LoadImaged,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandSpatialCropSamplesd,\n",
    "    RandShiftIntensityd,\n",
    "    RandZoomd,\n",
    "    ScaleIntensityd,\n",
    "    Spacingd,\n",
    "    SpatialPadd,\n",
    "    GaussianSmoothd,\n",
    "    RandRotate90d,\n",
    "    ToTensord,\n",
    "    RandSpatialCropd,\n",
    "    RandGaussianSmoothd,    \n",
    "    RandGaussianSharpend,\n",
    "    RandGaussianNoise,\n",
    "    \n",
    ")\n",
    "import nibabel as nib\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    ")\n",
    "from monai.metrics import MSEMetric as mse\n",
    "from monai.metrics import MAEMetric as mae\n",
    "from monai.metrics import PSNRMetric as psnr\n",
    "from monai.metrics import SSIMMetric as ssim\n",
    "from monai.metrics import RMSEMetric as rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbb1bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3986e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c571c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/T2_*.nii.gz')\n",
    "data_dir2 = glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/low_T2_*.nii.gz')\n",
    "data_dir3 = glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/syn_T2_*.nii.gz')\n",
    "valid_ind = np.arange(0, 6)\n",
    "#valid_ind = np.arange(25, 34)\n",
    "data_dicts = [\n",
    "    {\n",
    "        'image' : data_dir[i],\n",
    "        'low_res_image': data_dir2[i],\n",
    "        'syn' : data_dir3[i]\n",
    "         \n",
    "    }for i in valid_ind\n",
    "]\n",
    "valid_data = data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8fdfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "          transforms.LoadImaged(keys=[\"image\",'low_res_image','syn']),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\",\"low_res_image\",'syn']),\n",
    "        transforms.ScaleIntensityd(\n",
    "                keys=[\"image\",'low_res_image','syn'],\n",
    "                minv=0.0,\n",
    "                maxv=1.0,\n",
    "        ),           \n",
    "#         transforms.SpatialPadd(keys=['image','low_res_image'],spatial_size=(256,256,256)),\n",
    "        transforms.CenterSpatialCropd(keys=['image','low_res_image','syn'],roi_size = (192,220,192)),\n",
    "    ]\n",
    ")\n",
    "val_ds = CacheDataset(data=valid_data, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf823482",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = first(val_loader)\n",
    "fig, ax = plt.subplots(nrows=1,ncols=3)\n",
    "for i in range(1):\n",
    "    plt.subplot(131)\n",
    "    plt.title('image')\n",
    "    plt.imshow(check_data['image'][i,0,:,30,:],cmap = 'gray')\n",
    "    plt.subplot(132)\n",
    "    plt.title('low res image')\n",
    "    plt.imshow(check_data['low_res_image'][i,0,:,30,:],cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(133)\n",
    "    plt.title('syn image')\n",
    "    plt.imshow(check_data['syn'][i,0,:,30,:],cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4030f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.network_swinir import SwinIR as net\n",
    "\n",
    "model = monai.networks.nets.UNet(\n",
    "        spatial_dims=2,\n",
    "        in_channels=7,\n",
    "        out_channels=1,\n",
    "        channels=(64, 128, 256, 512),\n",
    "        strides=(2, 2, 2),\n",
    "        num_res_units=3,\n",
    "    ).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(\"./swinIR_weight/SwinUNetIR_v3.pth\")))\n",
    "# model.load_state_dict(torch.load(os.path.join(\"./High_res_UNet_v5_2.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256f36d",
   "metadata": {},
   "source": [
    "### PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1de7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.metrics import mean_absolute_error as mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1920c74c",
   "metadata": {},
   "source": [
    "### SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa31246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 import한 라이브러리들을 이용하여 계산\n",
    "\n",
    "\n",
    "model.eval()\n",
    "psnr_value = []\n",
    "ssim_value = []\n",
    "mse_value = []\n",
    "with torch.no_grad():\n",
    "    for step, batch in tqdm(enumerate(val_loader)):\n",
    "        # 기존 코드\n",
    "        rand = 30\n",
    "        iamges = batch['low_res_image'].to(device)\n",
    "        target = batch['image'].to(device)\n",
    "        val_output = batch['syn'].to(device)\n",
    "        \n",
    "#         images = batch['low_res_image']\n",
    "#         images = images.squeeze(1)\n",
    "#         images = images[...,rand:rand+7, :].to(device)\n",
    "#         images = images.permute(0,2,1,3)\n",
    "#         target = batch['image'][..., rand+3, :].to(device)\n",
    "        \n",
    "        \n",
    "        print(images.shape)\n",
    "        print(target.shape)\n",
    "        print(val_output.shape)\n",
    "        \n",
    "#         plt.subplot(141)\n",
    "#         plt.imshow(images[0,3,...].detach().cpu(),cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.title('input')\n",
    "\n",
    "#         plt.subplot(142)\n",
    "#         plt.imshow(target[0,0,...].detach().cpu(),cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.title('gt')\n",
    "\n",
    "#         plt.subplot(143)\n",
    "#         plt.imshow(val_output[0,0,:,rand,:].detach().cpu(),cmap='gray')\n",
    "#         plt.title('prediction')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         k = target[0,0,...]-val_output[0,...]\n",
    "#         k[k<0.01] = 0\n",
    "#         plt.subplot(144)\n",
    "#         plt.imshow(k.detach().cpu(),cmap='gray')\n",
    "#         plt.title('diff')\n",
    "#         plt.axis('off')\n",
    "# #         plt.colorbar()\n",
    "        \n",
    "        \n",
    "#         plt.show()\n",
    "\n",
    "#         val_output = val_output.cpu().numpy().squeeze()\n",
    "#         target = target.cpu().numpy().squeeze()\n",
    "# #         print(target.shape, val_output.shape)\n",
    "        \n",
    "\n",
    "#         # 모델 출력과 실제 타겟 이미지를 numpy 배열로 변환\n",
    "#         ssims = ssim(target,val_output[0,...],data_range = val_output.max()-val_output.min())\n",
    "#         psnrs = psnr(target,val_output[0,...],data_range = val_output.max()-val_output.min())\n",
    "#         maes = mae(target,val_output[0,...])\n",
    "#         print(maes)\n",
    "#         print(ssims)\n",
    "#         print(psnrs)\n",
    "#         # 각 이미지 별로 PSNR 및 SSIM 계산\n",
    "# #         for i in range(len(val_output)):\n",
    "           \n",
    "#         psnr_value.append(psnrs)\n",
    "#         ssim_value.append(ssims)\n",
    "#         mse_value.append(maes)\n",
    "\n",
    "# # # 결과 출력\n",
    "# average_psnr = sum(psnr_value)/len(psnr_value)\n",
    "# average_ssim = sum(ssim_value)/len(ssim_value)\n",
    "# average_mse = sum(mse_value)/len(mse_value)\n",
    "# print(f\"Average PSNR: {average_psnr}\")\n",
    "# print(f\"Average SSIM: {average_ssim}\")\n",
    "# print(f\"Average MSE : {average_mse}\")\n",
    "#     nifti_img = nib.load('/home/hufsbme/EA/bcp_t2_swinIR.nii.gz')\n",
    "#     image_data = nifti_img.get_fdata()\n",
    "#     low_res_nifti = nib.Nifti1Image(val_output, nifti_img.affine, nifti_img.header)\n",
    "\n",
    "#     nib.save(low_res_nifti,'/home/hufsbme/EA/test.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4354655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/origin/T2_0.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/improved/syn_T2_0_6.nii.gz\n",
      "tensor([[0.0005]])\n",
      "tensor([[32.7277]])\n",
      "0.8026460354007678\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/origin/T2_1.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/improved/syn_T2_1_6.nii.gz\n",
      "tensor([[0.0005]])\n",
      "tensor([[32.7509]])\n",
      "0.8288361178536099\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/origin/T2_2.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/improved/syn_T2_2_6.nii.gz\n",
      "tensor([[0.0004]])\n",
      "tensor([[33.5409]])\n",
      "0.7777278951364791\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/origin/T2_3.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/improved/syn_T2_3_6.nii.gz\n",
      "tensor([[0.0006]])\n",
      "tensor([[32.2008]])\n",
      "0.8910917651913712\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/origin/T2_4.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/improved/syn_T2_4_6.nii.gz\n",
      "tensor([[0.0073]])\n",
      "tensor([[21.3527]])\n",
      "0.7868253588394655\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/origin/T2_5.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/improved/syn_T2_5_6.nii.gz\n",
      "tensor([[0.0003]])\n",
      "tensor([[36.0142]])\n",
      "0.7945708088729803\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/origin/T2_6.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/improved/syn_T2_6_6.nii.gz\n",
      "tensor([[0.0009]])\n",
      "tensor([[30.2986]])\n",
      "0.8164431212463676\n",
      "tensor([[0.0015]]) tensor([[31.2694]]) 0.8140201575058631\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from monai.metrics import PSNRMetric as psnr\n",
    "import glob\n",
    "\n",
    "data_dir =  glob.glob('/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/origin/T2_*.nii.gz')\n",
    "data_dir2 = glob.glob('/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/low/low_T2_*.nii.gz')\n",
    "data_dir3 = glob.glob('/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/SwinIR/improved/syn_T2_*_6.nii.gz')\n",
    "\n",
    "k = mse()\n",
    "psnrs = psnr(max_val=1.0)\n",
    "# ssims = ssim(data_range=1.0)\n",
    "mse_value= []\n",
    "psnr_value = []\n",
    "ssim_value = []\n",
    "\n",
    "for i in range(len(data_dir)):\n",
    "    image1 = nib.load(data_dir[i])\n",
    "    image1 = image1.get_fdata()#216,101,208\n",
    "    image2 = nib.load(data_dir3[i])\n",
    "    image2 = image2.get_fdata()#216,101,208\n",
    "    \n",
    "    print(data_dir[i])\n",
    "    print(data_dir3[i])\n",
    "    \n",
    "    print(k(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    print(psnrs(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    s = ssim(image2,image1,data_range = image2.max()-image2.min())\n",
    "    print(s)\n",
    "#     print(SSIM(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    m = k(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    p = psnrs(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    \n",
    "#     s = SSIM(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    \n",
    "    mse_value.append(m)\n",
    "    psnr_value.append(p)\n",
    "    ssim_value.append(s)\n",
    "\n",
    "mean_mse = sum(mse_value)/len(mse_value)\n",
    "mean_psnr = sum(psnr_value)/len(psnr_value)\n",
    "mean_ssim = sum(ssim_value)/len(ssim_value)\n",
    "\n",
    "print(mean_mse,mean_psnr,mean_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc4fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/origin/T2_0.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/improved/syn_T2_0_6.nii.gz\n",
      "tensor([[0.0007]])\n",
      "tensor([[31.6232]])\n",
      "0.8079457212537325\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/origin/T2_1.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/improved/syn_T2_1_6.nii.gz\n",
      "tensor([[0.0003]])\n",
      "tensor([[35.8968]])\n",
      "0.8648696736773105\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/origin/T2_2.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/improved/syn_T2_2_6.nii.gz\n",
      "tensor([[0.0005]])\n",
      "tensor([[33.2229]])\n",
      "0.8210928785131121\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/origin/T2_3.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/improved/syn_T2_3_6.nii.gz\n",
      "tensor([[0.0006]])\n",
      "tensor([[32.1029]])\n",
      "0.8946014097249072\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/origin/T2_4.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/improved/syn_T2_4_6.nii.gz\n",
      "tensor([[0.0038]])\n",
      "tensor([[24.1683]])\n",
      "0.8256992905789317\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/origin/T2_5.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/improved/syn_T2_5_6.nii.gz\n",
      "tensor([[0.0002]])\n",
      "tensor([[36.7361]])\n",
      "0.7905002785959167\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/origin/T2_6.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/improved/syn_T2_6_6.nii.gz\n",
      "tensor([[0.0011]])\n",
      "tensor([[29.6602]])\n",
      "0.8323003237076866\n",
      "tensor([[0.0010]]) tensor([[31.9158]]) 0.8338585108645138\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from monai.metrics import PSNRMetric as psnr\n",
    "\n",
    "data_dir =  glob.glob('/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/origin/T2_*.nii.gz')\n",
    "data_dir2 = glob.glob('/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/low/low_T2_*.nii.gz')\n",
    "data_dir3 = glob.glob('/nfs/hufsaims/kjh_shared/euna/ISMRM/Result/UNet/improved/syn_T2_*_6.nii.gz')\n",
    "\n",
    "k = mse()\n",
    "psnrs = psnr(max_val=1.0)\n",
    "# ssims = ssim(data_range=1.0)\n",
    "mse_value= []\n",
    "psnr_value = []\n",
    "ssim_value = []\n",
    "\n",
    "for i in range(len(data_dir)):\n",
    "    image1 = nib.load(data_dir[i])\n",
    "    image1 = image1.get_fdata()#216,101,208\n",
    "    image2 = nib.load(data_dir3[i])\n",
    "    image2 = image2.get_fdata()#216,101,208\n",
    "    \n",
    "    print(data_dir[i])\n",
    "    print(data_dir3[i])\n",
    "    \n",
    "    print(k(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    print(psnrs(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    s = ssim(image2,image1,data_range = image2.max()-image2.min())\n",
    "    print(s)\n",
    "#     print(SSIM(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    m = k(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    p = psnrs(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    \n",
    "#     s = SSIM(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    \n",
    "    mse_value.append(m)\n",
    "    psnr_value.append(p)\n",
    "    ssim_value.append(s)\n",
    "\n",
    "mean_mse = sum(mse_value)/len(mse_value)\n",
    "mean_psnr = sum(psnr_value)/len(psnr_value)\n",
    "mean_ssim = sum(ssim_value)/len(ssim_value)\n",
    "\n",
    "print(mean_mse,mean_psnr,mean_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bca4353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/T2_25.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/syn_T2_25.nii.gz\n",
      "tensor([[0.0024]])\n",
      "0.80619912996896\n",
      "26.311794591600083\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/T2_24.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/syn_T2_24.nii.gz\n",
      "tensor([[0.0038]])\n",
      "0.6324213341396453\n",
      "20.856412299728934\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/T2_23.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/syn_T2_23.nii.gz\n",
      "tensor([[0.0033]])\n",
      "0.765459576911232\n",
      "24.329522063313323\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/T2_22.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/syn_T2_22.nii.gz\n",
      "tensor([[0.0050]])\n",
      "0.7823052070570302\n",
      "22.83518511610223\n",
      "tensor([[0.0036]]) 23.583228517686145 0.746596312019217\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "data_dir =  glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/T2_*.nii.gz')\n",
    "data_dir2 = glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/low_T2_*.nii.gz')\n",
    "data_dir3 = glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/syn_T2_*.nii.gz')\n",
    "\n",
    "k = mse()\n",
    "# psnrs = psnr(max_val=1.0)\n",
    "# ssims = ssim(data_range=1.0)\n",
    "mse_value= []\n",
    "psnr_value = []\n",
    "ssim_value = []\n",
    "\n",
    "for i in range(len(data_dir)):\n",
    "    image1 = nib.load(data_dir[i])\n",
    "    image1 = image1.get_fdata()#216,101,208\n",
    "    image2 = nib.load(data_dir3[i])\n",
    "    image2 = image2.get_fdata()#216,101,208\n",
    "    \n",
    "    print(data_dir[i])\n",
    "    print(data_dir3[i])\n",
    "    \n",
    "    print(k(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    s = ssim(image2,image1,data_range = image2.max()-image2.min())\n",
    "    print(s)\n",
    "#     print(SSIM(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    m = k(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    p = psnr(image2,image1,data_range = image2.max()-image2.min())\n",
    "    print(p)\n",
    "#     s = SSIM(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    \n",
    "    mse_value.append(m)\n",
    "    psnr_value.append(p)\n",
    "    ssim_value.append(s)\n",
    "\n",
    "mean_mse = sum(mse_value)/len(mse_value)\n",
    "mean_psnr = sum(psnr_value)/len(psnr_value)\n",
    "mean_ssim = sum(ssim_value)/len(ssim_value)\n",
    "\n",
    "print(mean_mse,mean_psnr,mean_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19454178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir/T2_25.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir/syn_T2_25.nii.gz\n",
      "tensor([[0.0022]])\n",
      "0.8275148311798214\n",
      "25.44016202784013\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir/T2_24.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir/syn_T2_24.nii.gz\n",
      "tensor([[0.0035]])\n",
      "0.6907297586807659\n",
      "17.95475810622414\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir/T2_23.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir/syn_T2_23.nii.gz\n",
      "tensor([[0.0024]])\n",
      "0.7593007468162184\n",
      "25.588175609997258\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir/T2_22.nii.gz\n",
      "/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir/syn_T2_22.nii.gz\n",
      "tensor([[0.0048]])\n",
      "0.7976494040181168\n",
      "21.99474917878483\n",
      "tensor([[0.0032]]) 22.74446123071159 0.7687986851737305\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "data_dir =  glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir/T2_*.nii.gz')\n",
    "data_dir2 = glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir//low_T2_*.nii.gz')\n",
    "data_dir3 = glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/swinir//syn_T2_*.nii.gz')\n",
    "\n",
    "k = mse()\n",
    "# psnrs = psnr(max_val=1.0)\n",
    "# ssims = ssim(data_range=1.0)\n",
    "mse_value= []\n",
    "psnr_value = []\n",
    "ssim_value = []\n",
    "\n",
    "for i in range(len(data_dir)):\n",
    "    image1 = nib.load(data_dir[i])\n",
    "    image1 = image1.get_fdata()#216,101,208\n",
    "    image2 = nib.load(data_dir3[i])\n",
    "    image2 = image2.get_fdata()#216,101,208\n",
    "    \n",
    "    print(data_dir[i])\n",
    "    print(data_dir3[i])\n",
    "    \n",
    "    print(k(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    s = ssim(image2,image1,data_range = image2.max()-image2.min())\n",
    "    print(s)\n",
    "#     print(SSIM(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0)))\n",
    "    m = k(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    p = psnr(image2,image1,data_range = image2.max()-image2.min())\n",
    "    print(p)\n",
    "#     s = SSIM(y_pred=torch.Tensor(image1).unsqueeze(0), y=torch.Tensor(image2).unsqueeze(0))\n",
    "    \n",
    "    mse_value.append(m)\n",
    "    psnr_value.append(p)\n",
    "    ssim_value.append(s)\n",
    "\n",
    "mean_mse = sum(mse_value)/len(mse_value)\n",
    "mean_psnr = sum(psnr_value)/len(psnr_value)\n",
    "mean_ssim = sum(ssim_value)/len(ssim_value)\n",
    "\n",
    "print(mean_mse,mean_psnr,mean_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9be346c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 101, 192)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad8df1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m\n\u001b[1;32m     30\u001b[0m     image2 \u001b[38;5;241m=\u001b[39m image2\u001b[38;5;241m.\u001b[39mget_fdata()\u001b[38;5;66;03m#216,101,208\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#     ssim_score = calculate_ssim(image1, image2)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#     psnr_score = calculate_psnr(image1, image2)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     mse_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_mse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     ssims \u001b[38;5;241m=\u001b[39m SSIM(image1,image2,data_range \u001b[38;5;241m=\u001b[39m val_output\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m-\u001b[39mval_output\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m     38\u001b[0m     psnrs \u001b[38;5;241m=\u001b[39m PSNR(image1,image2,data_range \u001b[38;5;241m=\u001b[39m val_output\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m-\u001b[39mval_output\u001b[38;5;241m.\u001b[39mmin())\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36mcalculate_mse\u001b[0;34m(image1, image2)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_mse\u001b[39m(image1, image2):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: mean(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "data_dir =  glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/T2_*.nii.gz')\n",
    "data_dir2 = glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/low_T2_*.nii.gz')\n",
    "data_dir3 = glob.glob('/nfs/hufsaims/kjh_shared/euna/data_bcp/improvement_result/unet/syn_T2_*.nii.gz')\n",
    "\n",
    "# SSIM (Structural Similarity Index) 계산 함수\n",
    "def calculate_ssim(image1, image2):\n",
    "    return ssim(image1, image2)\n",
    "\n",
    "# PSNR (Peak Signal-to-Noise Ratio) 계산 함수\n",
    "def calculate_psnr(image1, image2):\n",
    "    mse = torch.mean((image1 - image2) ** 2)\n",
    "    return 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "\n",
    "# MSE (Mean Squared Error) 계산 함수\n",
    "def calculate_mse(image1, image2):\n",
    "    return torch.mean((image1 - image2) ** 2)\n",
    "ss = []\n",
    "psnr_s = []\n",
    "mse_s = []\n",
    "\n",
    "for i in range(len(data_dir)):\n",
    "    image1 = nib.load(data_dir[i])\n",
    "    image1 = image1.get_fdata()#216,101,208\n",
    "    image2 = nib.load(data_dir3[i])\n",
    "    image2 = image2.get_fdata()#216,101,208\n",
    "    \n",
    "\n",
    "    \n",
    "#     ssim_score = calculate_ssim(image1, image2)\n",
    "#     psnr_score = calculate_psnr(image1, image2)\n",
    "    mse_score = calculate_mse(image1, image2)\n",
    "    ssims = SSIM(image1,image2,data_range = val_output.max()-val_output.min())\n",
    "    psnrs = PSNR(image1,image2,data_range = val_output.max()-val_output.min())\n",
    "    mses = calculate_mse(image1,image2)\n",
    "\n",
    "    ss.append(ssims)\n",
    "    psnr_s.append(psnrs)\n",
    "    mse_s.append(mses)\n",
    "\n",
    "\n",
    "avg_ss = sum(ss)/len(ss)\n",
    "avg_psnr = sum(psnr_s)/len(psnr_s)\n",
    "avg_mse = sum(mse_s)/len(mse_s)\n",
    "\n",
    "print(f'SSIM: {avg_ss:.4f}')\n",
    "print(f'PSNR: {avg_psnr:.4f} dB')\n",
    "print(f'MSE: {avg_mse:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for step, batch in tqdm(enumerate(val_loader)):\n",
    "        images = batch['image']\n",
    "        images = images.squeeze(1)\n",
    "        k = 192/2\n",
    "        plt.figure(dpi = 200)\n",
    "        plt.subplot(1,4,1)\n",
    "        plt.imshow(batch['image'][0,0, :, 140, :],cmap = 'gray')\n",
    "        plt.subplot(1,4,2)\n",
    "        plt.imshow(batch['image'][0,0, :, 105, :],cmap = 'gray')\n",
    "        plt.subplot(1,4,3)\n",
    "\n",
    "        plt.imshow(batch['image'][0,0,:,90, :],cmap = 'gray')\n",
    "        plt.subplot(1,4,4)\n",
    "\n",
    "        plt.imshow(batch['image'][0,0,:,65],cmap = 'gray')\n",
    "        plt.show()\n",
    "        print(images.shape)\n",
    "        plt.imshow(batch['image'][0,0,:,81,:],cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f71dc1",
   "metadata": {},
   "source": [
    "## interpolation과 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d61124",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for step, batch in tqdm(enumerate(val_loader)):\n",
    "        rand = 80\n",
    "        images = batch['low_res_image']\n",
    "        images = images.squeeze(1)\n",
    "        images = images[...,rand:rand+7, :].to(device)\n",
    "        images = images.permute(0,2,1,3)\n",
    "        target = batch['image'][..., rand+3, :].to(device)\n",
    "        val_output = model(images)\n",
    "#         print(images.shape)\n",
    "        nearest = torch.nn.functional.interpolate(images,size=(192,192),mode = 'nearest')\n",
    "        bilinear = torch.nn.functional.interpolate(images,size=(192,192),mode = 'bilinear')\n",
    "        bicubic = torch.nn.functional.interpolate(images,size=(192,192),mode = 'bicubic')\n",
    "#         linear = torch.nn.functional.interpolate(images,size=(192,192),mode = 'linear')\n",
    "        plt.figure(figsize=(15,3))\n",
    "\n",
    "        plt.subplot(141)\n",
    "        plt.imshow(val_output[0,0,...].detach().cpu(),cmap='gray')\n",
    "        plt.title('prediction')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(142)\n",
    "        plt.imshow(nearest[0,3,...].detach().cpu(),cmap='gray')\n",
    "        plt.title('Nearest')\n",
    "        plt.axis('off')\n",
    "\n",
    "        \n",
    "        plt.subplot(143)\n",
    "        plt.imshow(bilinear[0,3,...].detach().cpu(),cmap='gray')\n",
    "        plt.title('Bilinear')\n",
    "        plt.axis('off')\n",
    "\n",
    "        \n",
    "        \n",
    "        plt.subplot(144)\n",
    "        plt.imshow(bicubic[0,3,...].detach().cpu(),cmap='gray')\n",
    "        plt.title('Bicubic')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "        k_1  = target-val_output[0,3,...]\n",
    "        \n",
    "        k_1[k_1<0.01]=0\n",
    "\n",
    "        k_2 = target - nearest[0,3,...]\n",
    "\n",
    "        k_2[k_2<0.01]=0\n",
    "\n",
    "        k_3 = target - bilinear[0,3,...]\n",
    "\n",
    "        k_3[k_3<0.01]=0\n",
    "\n",
    "        k_4 = target - bicubic[0,3,...]\n",
    "                               \n",
    "\n",
    "        k_4[k_4<0.01]=0\n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(15,3))\n",
    "        \n",
    "        plt.subplot(1,4,1)\n",
    "        plt.imshow((np.abs(k_1[0,0,...].detach().cpu())/(target.max()-target.min())), cmap = 'jet', vmax = 0.1)\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "       \n",
    "        plt.subplot(142)\n",
    "        plt.imshow((np.abs(k_2[0,0,...].detach().cpu())/(target.max()-target.min())), cmap = 'jet', vmax = 0.1)\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(143)\n",
    "        plt.imshow((np.abs(k_3[0,0,...].detach().cpu())/(target.max()-target.min())), cmap = 'jet', vmax = 0.1)\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(144)\n",
    "        plt.imshow((np.abs(k_4[0,0,...].detach().cpu())/(target.max()-target.min())), cmap = 'jet', vmax = 0.1)\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        plt.subplot\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec206755",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = target-val_output[3,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "0~1 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "k[k<0.01]=0\n",
    "plt.imshow(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef391e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab266d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8612cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = [\n",
    "{\n",
    "    'image' : '/home/hufsbme/EA/T2.nii.gz'\n",
    "}      \n",
    "    ] \n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "          transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.ScaleIntensityd(\n",
    "                keys=[\"image\"],\n",
    "                minv=0.0,\n",
    "                maxv=1.0,\n",
    "        ),           \n",
    "#         transforms.SpatialPadd(keys=['image','low_res_image'],spatial_size=(256,256,256)),\n",
    "#         transforms.CenterSpatialCropd(keys=['image'],roi_size = (192,192,192)),\n",
    "    ]\n",
    ")\n",
    "test_ds = CacheDataset(data=test_dict, transform=val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(images[0,4,...].detach().cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17559060",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "psnr_value = []\n",
    "ssim_value = []\n",
    "with torch.no_grad():\n",
    "    for step, batch in tqdm(enumerate(test_loader)):\n",
    "        # 기존 코드\n",
    "        rand = 80\n",
    "        images = batch['image']\n",
    "        images = images.squeeze(1)\n",
    "        images = images[...,rand:rand+7, :].to(device)\n",
    "        print(images.shape)\n",
    "        images = images.permute(0,2,1,3)\n",
    "        target = batch['image'][..., rand+3, :].to(device)\n",
    "        \n",
    "        val_output = model(images)\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(images[0,4,...].detach().cpu(),cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('input')\n",
    "\n",
    "#         plt.subplot(132)\n",
    "#         plt.imshow(target[0,0,...].detach().cpu(),cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.title('gt')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(val_output[0,0,...].detach().cpu(),cmap='gray')\n",
    "        plt.title('prediction')\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        val_output = val_output.cpu().numpy().squeeze()\n",
    "        target = target.cpu().numpy().squeeze()\n",
    "\n",
    "        \n",
    "\n",
    "#         모델 출력과 실제 타겟 이미지를 numpy 배열로 변환\n",
    "        ssims = ssim(target,val_output,data_range = val_output.max()-val_output.min())\n",
    "        psnrs = psnr(target,val_output,data_range = val_output.max()-val_output.min())\n",
    "        print(ssims)\n",
    "        print(psnrs)\n",
    "        # 각 이미지 별로 PSNR 및 SSIM 계산\n",
    "#         for i in range(len(val_output)):\n",
    "           \n",
    "        psnr_value.append(psnrs)\n",
    "        ssim_value.append(ssims)\n",
    "\n",
    "# # 결과 출력\n",
    "average_psnr = sum(psnr_value)/len(psnr_value)\n",
    "average_ssim = sum(ssim_value)/len(ssim_value)\n",
    "print(f\"Average PSNR: {average_psnr}\")\n",
    "print(f\"Average SSIM: {average_ssim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nibabel as nib\n",
    "nifti_img = nib.load('/home/hufsbme/EA/T2.nii.gz')\n",
    "image_data = nifti_img.get_fdata()\n",
    "low_res_nifti = nib.Nifti1Image(val_output, nifti_img.affine, nifti_img.header)\n",
    "\n",
    "nib.save(low_res_nifti,'/home/hufsbme/EA/test.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d97ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
